{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c051e9b5",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffd527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shash\\OneDrive\\Desktop\\ai-and-sus\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import timm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca171c",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d85cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dir = 'output_dataset/train'\n",
    "val_dir = 'output_dataset/val'\n",
    "test_dir = 'output_dataset/test'\n",
    "\n",
    "# Hyperparameters\n",
    "MODEL_NAME = 'swinv2_tiny_window8_256'\n",
    "IMAGE_SIZE = 256\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Data loaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4636681",
   "metadata": {},
   "source": [
    "# 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64258484",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained Swin-Tiny model with classification head for 4 classes\n",
    "model = timm.create_model('swinv2_tiny_window8_256', pretrained=True, num_classes=4)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03469b",
   "metadata": {},
   "source": [
    "# 4. Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a57f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "train Loss: 1.3544 Acc: 42.8571\n",
      "val Loss: 1.2412 Acc: 50.0000\n",
      "\n",
      "Training complete in 2m 1s\n",
      "Best val Acc: 50.0000\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHS = 25\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "scaler = GradScaler()  # For AMP\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize history dictionary to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'), autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update() \n",
    "                    \n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc * 100:.4f}')\n",
    "\n",
    "            # Store in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())  # Convert tensor to float\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc * 100:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cf64a",
   "metadata": {},
   "source": [
    "# 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1fa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'swin_t_baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf075f",
   "metadata": {},
   "source": [
    "# 6. Prune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3473d",
   "metadata": {},
   "source": [
    "### 6.1 Load pretrained baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a59244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model without loading pretrained weights from ImageNet (we'll load our own)\n",
    "model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=False, num_classes=4)\n",
    "\n",
    "# Load your own saved trained weights\n",
    "model.load_state_dict(torch.load('swin_t_baseline.pth'))\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a2917",
   "metadata": {},
   "source": [
    "### 6.2 Prunning configuration with 30% Weights pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a19d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_and_remove(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Prunes 30% of weights in all Conv2d and Linear layers, then makes it permanent.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Apply unstructured L1 pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Remove the pruning mask and make it permanent\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_and_remove(model, amount=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ffb5a",
   "metadata": {},
   "source": [
    "### 6.3 Train pruned model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a28b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "train Loss: 1.2754 Acc: 50.2381\n",
      "val Loss: 1.2380 Acc: 50.0000\n",
      "\n",
      "Training complete in 2m 2s\n",
      "Best val Acc: 50.0000\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer for pruned model\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHS = 10  # or adjust as needed\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = torch.optim.AdamW(pruned_model.parameters(), lr=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler for pruned model\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "scaler = GradScaler()  # For AMP\n",
    "\n",
    "# Training function remains the same\n",
    "pruned_model, pruned_history = train_model(pruned_model, criterion, optimizer, scheduler, num_epochs=10)\n",
    "\n",
    "# Save pruned model\n",
    "torch.save(pruned_model.state_dict(), 'swin_t_pruned.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87844bb6",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac41dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 49.45054945054945%\n",
      "Pruned Model Accuracy: 49.45054945054945%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate baseline model\n",
    "model.load_state_dict(torch.load('swin_t_baseline.pth'))\n",
    "baseline_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Baseline Model Accuracy: {baseline_accuracy}%')\n",
    "\n",
    "# Evaluate pruned model\n",
    "model.load_state_dict(torch.load('swin_t_pruned.pth'))\n",
    "pruned_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Pruned Model Accuracy: {pruned_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f596d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fddcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
